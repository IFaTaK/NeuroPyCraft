{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# <span style=\"text-decoration: underline; font-weight: bold;\">Introduction to NeuroPyCraft: Building Neural Networks from the Ground Up</span>\n",
    "\n",
    "Welcome to **NeuroPyCraft**, an ambitious project dedicated to demystifying the intricate world of neural networks by building them from scratch. In the realm of artificial intelligence, neural networks are akin to a magic wand, capable of performing incredible feats across various domains. Yet, the true magic lies in understanding and crafting these powerful tools piece by piece.\n",
    "\n",
    "This document serves as a cornerstone of the NeuroPyCraft project. Our journey begins with the most basic element of neural networks â€” the single neuron. By dissecting its functionality and computational process, we aim to provide a thorough, ground-up understanding of how these individual units contribute to the complexity of larger neural systems. \n",
    "\n",
    "As the project progresses, we will scale our focus from the microcosm of a single neuron to the macrocosm of fully-fledged neural networks. You'll witness how simple neurons, when intricately connected and layered, give rise to systems capable of learning, adapting, and making decisions. \n",
    "\n",
    "NeuroPyCraft is more than just a theoretical exploration; it's a hands-on odyssey into the practicalities of neural network construction. By leveraging Python, we will not only discuss but also implement and visualize these concepts, making the abstract tangible and the complex understandable.\n",
    "\n",
    "This project is tailored for anyone with a spark of curiosity about neural networks, whether you're a student starting in AI, a professional enhancing your skill set, or an enthusiast eager to peek behind the curtain of machine learning technologies. NeuroPyCraft invites you to join this journey of discovery and innovation, where we unravel the mysteries of neural networks and harness their potential through code.\n",
    "\n",
    "<style>\n",
    "   body, p, ol {\n",
    "      max-inline-size: 75%;\n",
    "      writing-mode: horizontal-tb;\n",
    "      text-align: justify; \n",
    "      margin : 0% 0% 0% 5%;\n",
    "      }\n",
    "   h1 {\n",
    "      max-inline-size: 75%\n",
    "      text-align : center;\n",
    "      margin : 0% 0% 0% 5%;\n",
    "      }\n",
    "   h2 {\n",
    "      max-inline-size: 75%\n",
    "      margin : 0% 0% 0% 5%;\n",
    "      }\n",
    "   h3 {\n",
    "      max-inline-size: 75%\n",
    "      text-indent: 75px;\n",
    "      margin : 0% 0% 0% 5%;\n",
    "      }\n",
    "</style>\n",
    "\n",
    "## <h2 style=\"text-decoration: underline; font-weight: bold;\"> I - Computing the Output of our first neurons</h2>\n",
    "\n",
    "### <h3 style=\"text-decoration: underline; font-weight: bold;\"> 1 - Computing the Output of a single neuron</h3>\n",
    "\n",
    "Understanding the fundamental operation of a single neuron is crucial in grasping the basics of neural networks. This section breaks down the process into easily digestible steps, accompanied by visual representations and a practical Python example.\n",
    "\n",
    "Let's consider a neuron with three inputs, weights, and a bias. The inputs are $\\ [1, 2, 4]$, the corresponding weights are $\\ [7, 3, 2]$, and the bias is $\\ 0.5$. \n",
    "\n",
    "![Neural Network Graph](images/Compute1neuron1.png)\n",
    "\n",
    "Here's the step-by-step computation:\n",
    "\n",
    "1. **Calculate the Weighted Sum of Inputs**: \n",
    "   Multiply each input by its corresponding weight and sum these products with the bias. The formula is:\n",
    "\n",
    "   $\\\n",
    "   \\text{Weighted Sum} = (Input_1 \\times Weight_1) + (Input_2 \\times Weight_2) + (Input_3 \\times Weight_3) + Bias\n",
    "   $\n",
    "\n",
    "   Applying it to our example:\n",
    "\n",
    "   $\\\n",
    "   \\text{Weighted Sum} = (1 \\times 7) + (2 \\times 3) + (4 \\times 2) + 0.5 = 7 + 6 + 8 + 0.5 = 21.5\n",
    "   $\n",
    "\n",
    "![Neural Network Graph](images/Compute1neuron2.png)\n",
    "\n",
    "2. **Output of the Neuron**: \n",
    "   The neuron's output is the weighted sum. For our inputs, weights, and bias:\n",
    "\n",
    "   $\\\n",
    "   \\text{Neuron Output} = 21.5\n",
    "   $\n",
    "\n",
    "This value represents the neuron's linear response.\n",
    "\n",
    "![Neural Network Graph](images/Compute1neuron3.png)\n",
    "\n",
    "The following Python script illustrates this computation process in a practical manner, bridging the gap between theory and application:\n",
    "\n",
    "_Below is the Python script crafted to demonstrate the computation of a single neuron's output:_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output of the neuron: 21.5\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Define the inputs, weights, and bias\n",
    "inputs = [1, 2, 4]\n",
    "weights = [7, 3, 2]\n",
    "bias = 0.5\n",
    "\n",
    "# Calculating the weighted sum of inputs and bias\n",
    "weighted_sum = sum(i * w for i, w in zip(inputs, weights))\n",
    "neuron_output = weighted_sum + bias\n",
    "\n",
    "# Output of the neuron\n",
    "print(\"Output of the neuron:\", neuron_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
